{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpipe==3.3.1 in ./.venv/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: attrs<24.0.0,>=23.1.0 in ./.venv/lib/python3.10/site-packages (from openpipe==3.3.1) (23.1.0)\n",
      "Requirement already satisfied: openai<0.28.0,>=0.27.8 in ./.venv/lib/python3.10/site-packages (from openpipe==3.3.1) (0.27.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./.venv/lib/python3.10/site-packages (from openpipe==3.3.1) (2.8.2)\n",
      "Requirement already satisfied: httpx<0.25.0,>=0.24.1 in ./.venv/lib/python3.10/site-packages (from openpipe==3.3.1) (0.24.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx<0.25.0,>=0.24.1->openpipe==3.3.1) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in ./.venv/lib/python3.10/site-packages (from httpx<0.25.0,>=0.24.1->openpipe==3.3.1) (0.17.3)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx<0.25.0,>=0.24.1->openpipe==3.3.1) (3.4)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx<0.25.0,>=0.24.1->openpipe==3.3.1) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.8->openpipe==3.3.1) (3.8.6)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.8->openpipe==3.3.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.8->openpipe==3.3.1) (4.66.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->openpipe==3.3.1) (1.16.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./.venv/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.24.1->openpipe==3.3.1) (3.7.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.24.1->openpipe==3.3.1) (0.14.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->openpipe==3.3.1) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->openpipe==3.3.1) (3.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->openpipe==3.3.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->openpipe==3.3.1) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->openpipe==3.3.1) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->openpipe==3.3.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->openpipe==3.3.1) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.24.1->openpipe==3.3.1) (1.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpipe==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "hn = pl.read_parquet(\"data/hn.parquet\")\n",
    "stories = pl.read_parquet(\"data/stories-classified.parquet\")\n",
    "\n",
    "comments = hn.filter(\n",
    "    (pl.col(\"type\") == \"comment\")\n",
    "    & pl.col(\"deleted\").is_null()\n",
    "    & pl.col(\"dead\").is_null()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ai_ml</th><th>crypto</th><th>remote_work</th><th>rust</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>16593.0</td><td>8438.0</td><td>3132.0</td><td>4217.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌─────────┬────────┬─────────────┬────────┐\n",
       "│ ai_ml   ┆ crypto ┆ remote_work ┆ rust   │\n",
       "│ ---     ┆ ---    ┆ ---         ┆ ---    │\n",
       "│ f64     ┆ f64    ┆ f64         ┆ f64    │\n",
       "╞═════════╪════════╪═════════════╪════════╡\n",
       "│ 16593.0 ┆ 8438.0 ┆ 3132.0      ┆ 4217.0 │\n",
       "└─────────┴────────┴─────────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_cols = [\"ai_ml\", \"crypto\", \"remote_work\", \"rust\"]\n",
    "num_stories = stories.describe().filter(pl.col(\"describe\") == \"mean\")[tag_cols] * len(\n",
    "    stories\n",
    ")\n",
    "num_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ai_ml</th><th>crypto</th><th>remote_work</th><th>rust</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.277261e6</td><td>817174.0</td><td>379192.0</td><td>369599.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────┬──────────┬─────────────┬──────────┐\n",
       "│ ai_ml      ┆ crypto   ┆ remote_work ┆ rust     │\n",
       "│ ---        ┆ ---      ┆ ---         ┆ ---      │\n",
       "│ f64        ┆ f64      ┆ f64         ┆ f64      │\n",
       "╞════════════╪══════════╪═════════════╪══════════╡\n",
       "│ 1.277261e6 ┆ 817174.0 ┆ 379192.0    ┆ 369599.0 │\n",
       "└────────────┴──────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def applied_tag(tag_name):\n",
    "    return (\n",
    "        pl.when(\n",
    "            pl.col(\"top_level_parent\").is_in(stories.filter(pl.col(tag_name))[\"id\"])\n",
    "        )\n",
    "        .then(True)\n",
    "        .otherwise(False)\n",
    "        .alias(tag_name)\n",
    "    )\n",
    "\n",
    "\n",
    "comments = comments.with_columns([applied_tag(tag) for tag in tag_cols])\n",
    "\n",
    "num_comments = comments.describe().filter(pl.col(\"describe\") == \"mean\")[tag_cols] * len(\n",
    "    comments\n",
    ")\n",
    "num_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>2.817047e6</td></tr><tr><td>&quot;null_count&quot;</td><td>21283.0</td></tr><tr><td>&quot;mean&quot;</td><td>392.896374</td></tr><tr><td>&quot;std&quot;</td><td>449.83422</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>131.0</td></tr><tr><td>&quot;50%&quot;</td><td>260.0</td></tr><tr><td>&quot;75%&quot;</td><td>489.0</td></tr><tr><td>&quot;max&quot;</td><td>19371.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬────────────┐\n",
       "│ statistic  ┆ value      │\n",
       "│ ---        ┆ ---        │\n",
       "│ str        ┆ f64        │\n",
       "╞════════════╪════════════╡\n",
       "│ count      ┆ 2.817047e6 │\n",
       "│ null_count ┆ 21283.0    │\n",
       "│ mean       ┆ 392.896374 │\n",
       "│ std        ┆ 449.83422  │\n",
       "│ min        ┆ 0.0        │\n",
       "│ 25%        ┆ 131.0      │\n",
       "│ 50%        ┆ 260.0      │\n",
       "│ 75%        ┆ 489.0      │\n",
       "│ max        ┆ 19371.0    │\n",
       "└────────────┴────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_comments = comments.filter(\n",
    "    pl.col(\"ai_ml\") | pl.col(\"crypto\") | pl.col(\"remote_work\") | pl.col(\"rust\")\n",
    ")\n",
    "\n",
    "relevant_comments[\"text\"].str.len_chars().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_story_title = (\n",
    "    stories.filter(\n",
    "        pl.col(\"id\").is_in(relevant_comments[\"top_level_parent\"])\n",
    "        # pl.id(\"ai_ml\") | pl.col(\"crypto\") | pl.col(\"remote_work\") | pl.col(\"rust\")\n",
    "    )[[\"id\", \"title\"]]\n",
    "    .to_pandas()\n",
    "    .set_index(\"id\", drop=True)\n",
    ")[\"title\"].to_dict()\n",
    "\n",
    "id_to_text = (\n",
    "    relevant_comments[[\"id\", \"text\"]]\n",
    "    .to_pandas()\n",
    "    .set_index(\"id\", drop=True)[\"text\"]\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_817_047, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>type</th><th>by</th><th>time</th><th>title</th><th>text</th><th>url</th><th>score</th><th>parent</th><th>top_level_parent</th><th>descendants</th><th>kids</th><th>deleted</th><th>dead</th><th>ai_ml</th><th>crypto</th><th>remote_work</th><th>rust</th><th>story_title</th><th>parent_comment_text</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>list[i64]</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1026300</td><td>&quot;comment&quot;</td><td>&quot;lrm242&quot;</td><td>2010-01-01 21:49:27</td><td>null</td><td>&quot;This is a grea…</td><td>null</td><td>null</td><td>1.026228e6</td><td>1026228</td><td>null</td><td>[1026331, 1026782]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>null</td></tr><tr><td>1026331</td><td>&quot;comment&quot;</td><td>&quot;bradfordcross&quot;</td><td>2010-01-01 22:09:10</td><td>null</td><td>&quot;Thanks! Likewi…</td><td>null</td><td>null</td><td>1.0263e6</td><td>1026228</td><td>null</td><td>[1026389]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;This is a grea…</td></tr><tr><td>1026389</td><td>&quot;comment&quot;</td><td>&quot;lrm242&quot;</td><td>2010-01-01 22:49:18</td><td>null</td><td>&quot;Indeed. From t…</td><td>null</td><td>null</td><td>1.026331e6</td><td>1026228</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;Thanks! Likewi…</td></tr><tr><td>1026416</td><td>&quot;comment&quot;</td><td>&quot;felicisvc&quot;</td><td>2010-01-01 23:06:55</td><td>null</td><td>&quot;Thanks for thi…</td><td>null</td><td>null</td><td>1.026228e6</td><td>1026228</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>null</td></tr><tr><td>1026428</td><td>&quot;comment&quot;</td><td>&quot;ramanujan&quot;</td><td>2010-01-01 23:15:02</td><td>null</td><td>&quot;bradfordcross:…</td><td>null</td><td>null</td><td>1.026228e6</td><td>1026228</td><td>null</td><td>[1026543]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>null</td></tr><tr><td>1026543</td><td>&quot;comment&quot;</td><td>&quot;bradfordcross&quot;</td><td>2010-01-02 01:21:21</td><td>null</td><td>&quot;This is the sa…</td><td>null</td><td>null</td><td>1.026428e6</td><td>1026228</td><td>null</td><td>[1026733]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;bradfordcross:…</td></tr><tr><td>1026562</td><td>&quot;comment&quot;</td><td>&quot;jonmc12&quot;</td><td>2010-01-02 01:41:23</td><td>null</td><td>&quot;&quot;I want to swi…</td><td>null</td><td>null</td><td>1.026228e6</td><td>1026228</td><td>null</td><td>[1026739]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>null</td></tr><tr><td>1026733</td><td>&quot;comment&quot;</td><td>&quot;yannis&quot;</td><td>2010-01-02 03:53:37</td><td>null</td><td>&quot;It is a good a…</td><td>null</td><td>null</td><td>1.026543e6</td><td>1026228</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;This is the sa…</td></tr><tr><td>1026739</td><td>&quot;comment&quot;</td><td>&quot;sdrinf&quot;</td><td>2010-01-02 03:58:53</td><td>null</td><td>&quot;Um, no.&lt;p&gt;The …</td><td>null</td><td>null</td><td>1.026562e6</td><td>1026228</td><td>null</td><td>[1026793]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;&quot;I want to swi…</td></tr><tr><td>1026782</td><td>&quot;comment&quot;</td><td>&quot;johnl&quot;</td><td>2010-01-02 04:39:59</td><td>null</td><td>&quot;Yep, good plac…</td><td>null</td><td>null</td><td>1.0263e6</td><td>1026228</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;This is a grea…</td></tr><tr><td>1026793</td><td>&quot;comment&quot;</td><td>&quot;jonmc12&quot;</td><td>2010-01-02 04:53:12</td><td>null</td><td>&quot;The article wa…</td><td>null</td><td>null</td><td>1.026739e6</td><td>1026228</td><td>null</td><td>[1026877]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;Um, no.&lt;p&gt;The …</td></tr><tr><td>1026877</td><td>&quot;comment&quot;</td><td>&quot;sdrinf&quot;</td><td>2010-01-02 06:25:30</td><td>null</td><td>&quot;Picking single…</td><td>null</td><td>null</td><td>1.026793e6</td><td>1026228</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Beyond PageRan…</td><td>&quot;The article wa…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>38109433</td><td>&quot;comment&quot;</td><td>&quot;AuryGlenz&quot;</td><td>2023-11-02 05:48:28</td><td>null</td><td>&quot;I think there&amp;…</td><td>null</td><td>null</td><td>3.8102462e7</td><td>38085289</td><td>null</td><td>null</td><td>null</td><td>null</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;California emp…</td><td>&quot;Except when th…</td></tr><tr><td>38109437</td><td>&quot;comment&quot;</td><td>&quot;Barrin92&quot;</td><td>2023-11-02 05:49:12</td><td>null</td><td>&quot;&amp;gt;But wouldn…</td><td>null</td><td>null</td><td>3.8109397e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;The moat he de…</td></tr><tr><td>38109441</td><td>&quot;comment&quot;</td><td>&quot;sgu999&quot;</td><td>2023-11-02 05:49:42</td><td>null</td><td>&quot;We are already…</td><td>null</td><td>null</td><td>3.8109352e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;Eh, the strong…</td></tr><tr><td>38109442</td><td>&quot;comment&quot;</td><td>&quot;chrismarlow9&quot;</td><td>2023-11-02 05:49:57</td><td>null</td><td>&quot;Why do you nee…</td><td>null</td><td>null</td><td>3.8109381e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;Training is st…</td></tr><tr><td>38109444</td><td>&quot;comment&quot;</td><td>&quot;rhizome&quot;</td><td>2023-11-02 05:50:17</td><td>null</td><td>&quot;Cost of techno…</td><td>null</td><td>null</td><td>3.8109215e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;It&amp;#x27;s too …</td></tr><tr><td>38109445</td><td>&quot;comment&quot;</td><td>&quot;artninja1988&quot;</td><td>2023-11-02 05:50:21</td><td>null</td><td>&quot;P(doom)=0.3 ac…</td><td>null</td><td>null</td><td>3.8109408e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;That&amp;#x27;s th…</td></tr><tr><td>38109454</td><td>&quot;comment&quot;</td><td>&quot;Geee&quot;</td><td>2023-11-02 05:51:37</td><td>null</td><td>&quot;Yeah, it is a …</td><td>null</td><td>null</td><td>3.8108873e7</td><td>38108873</td><td>null</td><td>[38109464]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>null</td></tr><tr><td>38109464</td><td>&quot;comment&quot;</td><td>&quot;a_t48&quot;</td><td>2023-11-02 05:52:37</td><td>null</td><td>&quot;This would mak…</td><td>null</td><td>null</td><td>3.8109454e7</td><td>38108873</td><td>null</td><td>[38109491]</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;Yeah, it is a …</td></tr><tr><td>38109471</td><td>&quot;comment&quot;</td><td>&quot;mrexroad&quot;</td><td>2023-11-02 05:54:31</td><td>null</td><td>&quot;Either way, it…</td><td>null</td><td>null</td><td>3.8109381e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;Training is st…</td></tr><tr><td>38109477</td><td>&quot;comment&quot;</td><td>&quot;lazzlazzlazz&quot;</td><td>2023-11-02 05:55:36</td><td>null</td><td>&quot;The way incumb…</td><td>null</td><td>null</td><td>3.8108873e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>null</td></tr><tr><td>38109479</td><td>&quot;comment&quot;</td><td>&quot;riku_iki&quot;</td><td>2023-11-02 05:56:11</td><td>null</td><td>&quot;I didn&amp;#x27;t …</td><td>null</td><td>null</td><td>3.8109429e7</td><td>38105839</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;The business o…</td><td>&quot;I&amp;#x27;d say i…</td></tr><tr><td>38109491</td><td>&quot;comment&quot;</td><td>&quot;dotnet00&quot;</td><td>2023-11-02 05:57:10</td><td>null</td><td>&quot;Or it would cr…</td><td>null</td><td>null</td><td>3.8109464e7</td><td>38108873</td><td>null</td><td>null</td><td>null</td><td>null</td><td>true</td><td>false</td><td>false</td><td>false</td><td>&quot;Yann LeCun: AI…</td><td>&quot;This would mak…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_817_047, 20)\n",
       "┌──────────┬─────────┬─────────────┬────────────┬───┬────────────┬───────┬────────────┬────────────┐\n",
       "│ id       ┆ type    ┆ by          ┆ time       ┆ … ┆ remote_wor ┆ rust  ┆ story_titl ┆ parent_com │\n",
       "│ ---      ┆ ---     ┆ ---         ┆ ---        ┆   ┆ k          ┆ ---   ┆ e          ┆ ment_text  │\n",
       "│ i64      ┆ str     ┆ str         ┆ datetime[μ ┆   ┆ ---        ┆ bool  ┆ ---        ┆ ---        │\n",
       "│          ┆         ┆             ┆ s]         ┆   ┆ bool       ┆       ┆ str        ┆ str        │\n",
       "╞══════════╪═════════╪═════════════╪════════════╪═══╪════════════╪═══════╪════════════╪════════════╡\n",
       "│ 1026300  ┆ comment ┆ lrm242      ┆ 2010-01-01 ┆ … ┆ false      ┆ false ┆ Beyond     ┆ null       │\n",
       "│          ┆         ┆             ┆ 21:49:27   ┆   ┆            ┆       ┆ PageRank:  ┆            │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ Learning   ┆            │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ with C…    ┆            │\n",
       "│ 1026331  ┆ comment ┆ bradfordcro ┆ 2010-01-01 ┆ … ┆ false      ┆ false ┆ Beyond     ┆ This is a  │\n",
       "│          ┆         ┆ ss          ┆ 22:09:10   ┆   ┆            ┆       ┆ PageRank:  ┆ great      │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ Learning   ┆ article. I │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ with C…    ┆ poste…     │\n",
       "│ 1026389  ┆ comment ┆ lrm242      ┆ 2010-01-01 ┆ … ┆ false      ┆ false ┆ Beyond     ┆ Thanks!    │\n",
       "│          ┆         ┆             ┆ 22:49:18   ┆   ┆            ┆       ┆ PageRank:  ┆ Likewise - │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ Learning   ┆ the        │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ with C…    ┆ filtering… │\n",
       "│ 1026416  ┆ comment ┆ felicisvc   ┆ 2010-01-01 ┆ … ┆ false      ┆ false ┆ Beyond     ┆ null       │\n",
       "│          ┆         ┆             ┆ 23:06:55   ┆   ┆            ┆       ┆ PageRank:  ┆            │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ Learning   ┆            │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ with C…    ┆            │\n",
       "│ …        ┆ …       ┆ …           ┆ …          ┆ … ┆ …          ┆ …     ┆ …          ┆ …          │\n",
       "│ 38109471 ┆ comment ┆ mrexroad    ┆ 2023-11-02 ┆ … ┆ false      ┆ false ┆ Yann       ┆ Training   │\n",
       "│          ┆         ┆             ┆ 05:54:31   ┆   ┆            ┆       ┆ LeCun: AI  ┆ is still   │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ one-percen ┆ very       │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ ters se…   ┆ expensive… │\n",
       "│ 38109477 ┆ comment ┆ lazzlazzlaz ┆ 2023-11-02 ┆ … ┆ false      ┆ false ┆ Yann       ┆ null       │\n",
       "│          ┆         ┆ z           ┆ 05:55:36   ┆   ┆            ┆       ┆ LeCun: AI  ┆            │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ one-percen ┆            │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ ters se…   ┆            │\n",
       "│ 38109479 ┆ comment ┆ riku_iki    ┆ 2023-11-02 ┆ … ┆ false      ┆ false ┆ The        ┆ I&#x27;d   │\n",
       "│          ┆         ┆             ┆ 05:56:11   ┆   ┆            ┆       ┆ business   ┆ say        │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ of         ┆ it&#x27;s  │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ extracting ┆ less like… │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ knowl…     ┆            │\n",
       "│ 38109491 ┆ comment ┆ dotnet00    ┆ 2023-11-02 ┆ … ┆ false      ┆ false ┆ Yann       ┆ This would │\n",
       "│          ┆         ┆             ┆ 05:57:10   ┆   ┆            ┆       ┆ LeCun: AI  ┆ make AI    │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ one-percen ┆ usage      │\n",
       "│          ┆         ┆             ┆            ┆   ┆            ┆       ┆ ters se…   ┆ restric…   │\n",
       "└──────────┴─────────┴─────────────┴────────────┴───┴────────────┴───────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_comments = relevant_comments.with_columns(\n",
    "    [\n",
    "        pl.col(\"top_level_parent\").map_dict(id_to_story_title).alias(\"story_title\"),\n",
    "        pl.col(\"parent\")\n",
    "        .cast(pl.Int64)\n",
    "        .map_dict(id_to_text, return_dtype=str)\n",
    "        .alias(\"parent_comment_text\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "relevant_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_inputs(row, topic):\n",
    "    expanded_topic = {\n",
    "        \"ai_ml\": \"AI and ML\",\n",
    "        \"crypto\": \"blockchain/crypto\",\n",
    "        \"remote_work\": \"remote work\",\n",
    "        \"rust\": \"Rustlang\",\n",
    "    }[topic]\n",
    "\n",
    "    parent_text = (\n",
    "        f\"PARENT COMMENT:\\n{row['parent_comment_text']}\"\n",
    "        if row[\"parent_comment_text\"]\n",
    "        else f\"PARENT STORY:\\n{row['story_title']}\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You will be given an HN child comment and its parent. Do your best to determine the sentiment of the CHILD COMMENT towards <<{expanded_topic}>>.\\n\\nIf you are unsure or the CHILD COMMENT doesn't express an opinion on {expanded_topic} assume 'neutral' by default.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{parent_text}\\n---\\nCHILD COMMENT:\\n{row['text']}\",\n",
    "        },\n",
    "    ]\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"classify\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sentiment\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"positive\", \"neutral\", \"negative\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"sentiment\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    function_call = {\"name\": \"classify\"}\n",
    "\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"functions\": functions,\n",
    "        \"function_call\": function_call,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ai_ml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing crypto\n",
      "Processing remote_work\n",
      "Processing rust\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>tag</th><th>input</th></tr><tr><td>i64</td><td>str</td><td>struct[3]</td></tr></thead><tbody><tr><td>1026300</td><td>&quot;ai_ml&quot;</td><td>{[{&quot;system&quot;,&quot;You will be given an HN child comment and its parent. Do your best to determine the sentiment of the CHILD COMMENT towards &lt;&lt;AI and ML&gt;&gt;.\n",
       "\n",
       "If you are unsure or the CHILD COMMENT doesn&#x27;t express an opinion on AI and ML assume &#x27;neutral&#x27; by default.&quot;}, {&quot;user&quot;,&quot;PARENT STORY:\n",
       "Beyond PageRank: Learning with Content and Networks\n",
       "---\n",
       "CHILD COMMENT:\n",
       "This is a great article. I posted on the same topic but different perspective today as well: &lt;a href=&quot;http://fitnr.com/filtering-the-web-of-noise/&quot; rel=&quot;nofollow&quot;&gt;http://fitnr.com/filtering-the-web-of-noise/&lt;/a&gt;&quot;}],[{&quot;classify&quot;,{&quot;object&quot;,{{&quot;string&quot;,[&quot;positive&quot;, &quot;neutral&quot;, &quot;negative&quot;]}},[&quot;sentiment&quot;]}}],{&quot;classify&quot;}}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌─────────┬───────┬───────────────────────────────────┐\n",
       "│ id      ┆ tag   ┆ input                             │\n",
       "│ ---     ┆ ---   ┆ ---                               │\n",
       "│ i64     ┆ str   ┆ struct[3]                         │\n",
       "╞═════════╪═══════╪═══════════════════════════════════╡\n",
       "│ 1026300 ┆ ai_ml ┆ {[{\"system\",\"You will be given a… │\n",
       "└─────────┴───────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shared import serialize_input\n",
    "import os\n",
    "\n",
    "comments_to_classify = None\n",
    "\n",
    "path = \"data/comments-to-classify.ndjson\"\n",
    "\n",
    "if os.path.exists(path):\n",
    "    comments_to_classify = pl.read_ndjson(path)\n",
    "else:\n",
    "    for tag in tag_cols:\n",
    "        print(f\"Processing {tag}\")\n",
    "        tag_comments = (\n",
    "            relevant_comments.filter(pl.col(tag)).with_columns(\n",
    "                pl.struct(pl.all())\n",
    "                .map_elements(lambda row: get_completion_inputs(row, tag))\n",
    "                .alias(\"input\"),\n",
    "                pl.lit(tag).alias(\"tag\"),\n",
    "            )\n",
    "        )[[\"id\", \"tag\", \"input\"]]\n",
    "        if comments_to_classify is None:\n",
    "            comments_to_classify = tag_comments\n",
    "        else:\n",
    "            comments_to_classify = comments_to_classify.vstack(tag_comments)\n",
    "\n",
    "    comments_to_classify.write_ndjson(path)\n",
    "comments_to_classify.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_comments = comments_to_classify.sample(20000, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-03 00:35:49] HTTP Request: POST https://app.openpipe.ai/api/v1/report \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8GcS2LCBLDNMkytaJmC4XOuheiLUM at 0x7f242a9f80e0> JSON: {\n",
       "  \"id\": \"chatcmpl-8GcS2LCBLDNMkytaJmC4XOuheiLUM\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1698971746,\n",
       "  \"model\": \"gpt-4-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": null,\n",
       "        \"function_call\": {\n",
       "          \"name\": \"classify\",\n",
       "          \"arguments\": \"{\\n\\\"sentiment\\\": \\\"positive\\\"\\n}\"\n",
       "        }\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 236,\n",
       "    \"completion_tokens\": 9,\n",
       "    \"total_tokens\": 245\n",
       "  },\n",
       "  \"openpipe\": {\n",
       "    \"cache_status\": \"SKIP\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Memory\n",
    "import openpipe\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openpipe.configure_openpipe(api_key=os.getenv(\"OPENPIPE_API_KEY\"))\n",
    "\n",
    "openpipe.openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "memory = Memory(\"/workspace/cache/hn_comment_sentiment_analysis\", verbose=0)\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def classify_comment(row):\n",
    "    resp = openpipe.openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        **row[\"input\"],\n",
    "        openpipe={\"tags\": {\"prompt_id\": \"classify_hn_comment_v10\"}},\n",
    "    )\n",
    "\n",
    "    json.loads(resp.choices[0].message.function_call.arguments)\n",
    "    return resp\n",
    "\n",
    "\n",
    "classify_comment(training_comments[0].to_dicts()[0])\n",
    "\n",
    "# print(training_comments[0].to_dicts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/20000 [00:00<1:26:37,  3.85it/s]Exception ignored in: <function _releaseLock at 0x7f44648b81f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "  0%|          | 20/20000 [00:05<1:28:52,  3.75it/s]"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ai_ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_2382332/2577155717.py\", line 12, in process_input\nKeyError: 'ai_ml'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m                 \u001b[39mprint\u001b[39m(e)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m row\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m gpt4_labeled_comments \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     delayed(process_input)(row)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m row \u001b[39min\u001b[39;49;00m tqdm\u001b[39m.\u001b[39;49mtqdm(training_comments\u001b[39m.\u001b[39;49mhead(\u001b[39m20000\u001b[39;49m)\u001b[39m.\u001b[39;49mrows(named\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m gpt4_labeled_comments \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mDataFrame(gpt4_labeled_comments)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdev1/workspace/opipe-experiments/hn-analysis/generate-sentiment-analysis-training-data.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m gpt4_labeled_comments\n",
      "File \u001b[0;32m/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[1;32m   1700\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[1;32m    738\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/workspace/opipe-experiments/hn-analysis/.venv/lib/python3.10/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ai_ml'"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "training_data = []\n",
    "\n",
    "\n",
    "def process_input(row):\n",
    "    for tag in tag_cols:\n",
    "        row[f\"sentiment_{tag}\"] = None\n",
    "        if row[tag]:\n",
    "            try:\n",
    "                output = classify_comment(row, tag)\n",
    "                sentiment = json.loads(\n",
    "                    output.choices[0].message[\"function_call\"][\"arguments\"]\n",
    "                )[\"sentiment\"]\n",
    "                row[f\"sentiment_{tag}\"] = sentiment\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return row\n",
    "\n",
    "\n",
    "gpt4_labeled_comments = Parallel(n_jobs=20)(\n",
    "    delayed(process_input)(row)\n",
    "    for row in tqdm.tqdm(training_comments.head(20000).rows(named=True))\n",
    ")\n",
    "gpt4_labeled_comments = pl.DataFrame(gpt4_labeled_comments)\n",
    "gpt4_labeled_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_labeled_comments.write_parquet(\"data/labeled-comments.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hn-analysis-9rBFKxKV-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
